---
title: "Sample Size Estimate Based on Number of Trials"
author: "Trisha N. Patel"
runtime: shiny
output: html_document
---
Finding a sample size for your experiment can be a tricky process. You will probably find yourself sifting through previous research in hopes of stumbling across a similar experimental design. Best case scenario, you generate an estimate for the effect size you are expecting to find. Unfortunately, basing your sample size solely on an estimated effect size fails to take into account the added complexity of the number of trials per subject.

The simulation below uses the estimated effect size and the number of trials to find the required sample size to achieve a particular level of power.

1. Two groups of data are generated by random sampling from two normal distributions separated by a given effect size.
2. To represent overall performance for a given individual, these values are logistically transformed to obtain a value between 0 and 1.
3. To simulate variability across trials, these performance values are used as a binomial probability. This represents success across trials for a given subject. 
4. The mean of the simulated binomial probability data was saved for each subject. This represents the sample performance measure. 
5. A two sample t-test is used to compare performance across the two groups. 
6. This simulation is repeated either 100 or 1,000 times for each sample size ranging from 10 to 200. Power is defined as the probability of obtaining a p<.05 across all simulations for each sample size. 

While this is demonstrated using a two groups, this method can be adapted to more complex designs.

### Simulation Inputs

```{r echo = FALSE}

               
sliderInput("nt", label = "Number of Trials:",
              min = 1, max = 500, value = 100, step = 1,width='100%')

sliderInput("es", label = "Effect Size:",
              min = 0, max = 2, value = 0.3, step = 0.01,width='100%')

radioButtons("nsim", label= "Number of Simulations in a Sample", choices = c("100", "1000"), inline= TRUE)
```

```{r echo = FALSE}
sampleRec <- function(d, trials, simnumber) {
  
  #numSim = 1000
  numSim = simnumber
  samplesize = seq(from=10, to=200, by=10)
  ttdata = integer(numSim)
  caleff = integer(numSim)
  powers = integer(length(samplesize))
  newd = integer(length(samplesize))
  
  #for each sample size, run 1000 simulations
  for (ss in 1:length(samplesize)) {
    
    for (sim in 1:numSim) {
      #sample size of interest
      numSubs = samplesize[ss]
      
      #generate values for each subject
      treat = rnorm(numSubs/2,d) #self pacing condition, better with effect size
      control = rnorm(numSubs/2,0) #rnorm(numSubs/2) #yoked condition
      
      treat2 = integer(length(treat))
      control2 = integer(length(control))
      
      #turn values into probabilities to generate binomial dist (logistic)
      for (i in 1:length(treat)) {
        treat2[i] = 1/(1+exp(-1*(treat[i]-0)))
        control2[i] = 1/(1+exp(-1*(control[i]-0)))
      }
      
      treat = treat2
      control = control2
      
      #array for simulated performance values
      treat_perf = integer(numSubs/2)
      control_perf = integer(numSubs/2)
      
      #generate binomial and calc average per subject
      for (s in 1:(numSubs/2)){
        x1 = floor(trials*treat[s])
        x2 = floor(trials*control[s])
        
        #treat_perf[s] = mean(rbinom(n=trials, size =1, prob = treat[s])) #[1,0,0,1,...]
        #control_perf[s] = mean(rbinom(n=trials, size =1, prob = control[s]))
        
        #this spits out number of suc based on probs (produced same results)
        treat_perf[s] = rbinom(1, size=trials, prob=treat[s])/trials
        control_perf[s] = rbinom(1, size=trials, prob=control[s])/trials
      }
      
      #do a t-test and save p value
      ttdata[sim] = t.test(treat_perf,control_perf)$p.value
      
      #calc effect size
      caleff[sim] = (mean(treat_perf) - mean(control_perf))/sqrt((sd(control_perf)^2 + sd(treat_perf)^2)/2)
    }
    
    #calculate power and resulting effect size
    powers[ss] = length(which(ttdata<.05))/numSim
    #print(length(which(ttdata<.05))/numSim)
    newd[ss] = mean(caleff)
    
  }
  
  #min sample needed for power 80%
  minsample = samplesize[which(powers>.8)[1]]
  
  #print some info to console
  #print(d)
  #print(minsample)
  #print(mean(newd))
  
  #return(c(minsample,mean(newd)))
  return(data.frame("xvalues" = samplesize, "yvalues" = powers))
  #return(treat)
}
```

```{r echo = FALSE}
renderPlot({
  
  sample <- sampleRec(input$es,input$nt,as.numeric(input$nsim))
  
  plot(sample$xvalues, sample$yvalues, type = "b", pch = 19, 
     col = "skyblue4", xlab = "Total Number of Subjects", ylab = "Power", ylim=c(0,1), xlim=c(10,200))
  
  lines(sample$xvalues, rep(0.8, length(sample$xvalues)), type="l", lty=2)
})
```